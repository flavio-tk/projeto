{"cells":[{"cell_type":"markdown","source":["# Carga Camada Bronze"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"1cb28533-d78f-4c04-8a1a-566c8e48b814","inputWidgets":{},"title":""}}},{"cell_type":"code","source":["from pyspark.sql.functions import lit, col\nfrom pyspark.sql.types import StructType, StructField, StringType\nfrom datetime import datetime, timedelta\nfrom delta.tables import DeltaTable"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{"rowLimit":10000,"byteLimit":2048000},"nuid":"2d6f1fc0-8911-47a1-b0b0-7a06ab702985","inputWidgets":{},"title":""}},"outputs":[],"execution_count":0},{"cell_type":"code","source":["current_date = datetime.now()\n\n# Calcula o início do mês anterior\nprevious_month = current_date.replace(day=1) - timedelta(days=1)\nyear_month = previous_month.strftime(\"%Y%m\")\nyear = previous_month.strftime(\"%Y\")\nmonth = str(int(previous_month.strftime(\"%m\")))\nbegin_previous_month = previous_month.replace(day=1).strftime(\"%Y%m%d\")\n\n# Calcula o fim do mês anterior\nend_previous_month = previous_month.strftime(\"%Y%m%d\")\n\nprint(year_month)\nprint(year)\nprint(month)"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{"rowLimit":10000,"byteLimit":2048000},"nuid":"78a55490-4cdf-4d26-9e09-bd08a61a4741","inputWidgets":{},"title":""}},"outputs":[{"output_type":"stream","output_type":"stream","name":"stdout","text":["202305\n2023\n5\n"]}],"execution_count":0},{"cell_type":"code","source":["delta_table_path = \"/mnt/projeto_climatico/bronze/nasa_solar_flux_temperature\"\ncondicao_exclusao = f\"YEAR = {year} AND MO = {month}\"\ndelta_table = DeltaTable.forPath(spark, delta_table_path)\ndelta_table.delete(condicao_exclusao)"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":true,"cellMetadata":{},"nuid":"6c08669f-7661-4849-84b2-33e3f6fc7d01","inputWidgets":{},"title":"Exclusao do Ano Mes a ser processado ou reprocessado"}},"outputs":[],"execution_count":0},{"cell_type":"code","source":["caminho_arquivo = \"dbfs:/mnt/projeto_climatico/landing/nasa_solar_flux_temperature/\" + year + \"/nasa_solar_flux_temperature_\" + year_month + \".csv\"\n\nrdd = spark.sparkContext.textFile(caminho_arquivo)\n\n# Filtra as linhas após a linha \"-END HEADER-\"\nheader_end_index = rdd.collect().index(\"-END HEADER-\")\nlinhas = rdd.collect()[header_end_index + 1:]\n\n# Obtém o cabeçalho do arquivo\nheader = linhas[0]\n\n# Remove a linha do cabeçalho\nlinhas = linhas[1:]\n\n# Define o esquema original\nschema = StructType([\n    StructField(\"YEAR\", StringType(), True),\n    StructField(\"MO\", StringType(), True),\n    StructField(\"DY\", StringType(), True),\n    StructField(\"ALLSKY_SFC_SW_DWN\", StringType(), True),\n    StructField(\"CLRSKY_SFC_SW_DWN\", StringType(), True),\n    StructField(\"ALLSKY_KT\", StringType(), True),\n    StructField(\"ALLSKY_SFC_LW_DWN\", StringType(), True),\n    StructField(\"ALLSKY_SFC_PAR_TOT\", StringType(), True),\n    StructField(\"CLRSKY_SFC_PAR_TOT\", StringType(), True),\n    StructField(\"ALLSKY_SFC_UVA\", StringType(), True),\n    StructField(\"ALLSKY_SFC_UVB\", StringType(), True),\n    StructField(\"ALLSKY_SFC_UV_INDEX\", StringType(), True),\n    StructField(\"T2M\", StringType(), True),\n    StructField(\"T2MDEW\", StringType(), True),\n    StructField(\"T2MWET\", StringType(), True),\n    StructField(\"TS\", StringType(), True),\n    StructField(\"T2M_RANGE\", StringType(), True),\n    StructField(\"T2M_MAX\", StringType(), True),\n    StructField(\"T2M_MIN\", StringType(), True) \n])\n\n# Verifica se o número de colunas no arquivo corresponde ao número de colunas no esquema\nnum_colunas_arquivo = len(header.split(','))\nnum_colunas_esquema = len(schema.fields)\n\nif num_colunas_arquivo == num_colunas_esquema:\n    # As colunas do arquivo correspondem ao esquema original\n    rdd_temp = spark.sparkContext.parallelize(linhas).map(lambda line: tuple(line.split(',')))\nelse:\n    # As colunas do arquivo são diferentes do esquema original\n    schema = StructType([StructField(col_name, StringType(), True) for col_name in header.split(',')])\n    rdd_temp = spark.sparkContext.parallelize(linhas).map(lambda line: tuple(line.split(',')))\n\n# Converte o RDD em DataFrame usando o esquema\ndf_temp = spark.createDataFrame(rdd_temp, schema)\n\ndf_temp = df_temp.withColumn(\"YEAR\", col(\"YEAR\").cast(\"int\"))\n"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"f8d6a86a-f4d2-4f3a-9f54-5efed80269e2","inputWidgets":{},"title":""}},"outputs":[],"execution_count":0},{"cell_type":"code","source":["df_temp.write.mode(\"append\").option(\"path\", \"/mnt/projeto_climatico/bronze/nasa_solar_flux_temperature\").format(\"delta\").saveAsTable(\"bronze.nasa_solar_flux_temperature\")"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"0bd3e264-fce9-488f-84a3-c4e1b408d0de","inputWidgets":{},"title":""}},"outputs":[],"execution_count":0},{"cell_type":"code","source":["%sql\nOPTIMIZE bronze.nasa_solar_flux_temperature"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"816ceada-8535-426c-9f2b-04d23540ff53","inputWidgets":{},"title":""}},"outputs":[],"execution_count":0}],"metadata":{"application/vnd.databricks.v1+notebook":{"notebookName":"02_NASA_POWER_WEATHER_INGESTAO_CARGA_MENSAL_BRONZE","dashboards":[],"notebookMetadata":{"pythonIndentUnit":4},"language":"python","widgets":{}}},"nbformat":4,"nbformat_minor":0}
